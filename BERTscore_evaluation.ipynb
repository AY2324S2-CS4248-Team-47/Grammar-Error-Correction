{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCI8WzzaazPC"
      },
      "source": [
        "BERTScore\n",
        "\n",
        "Referenced from https://www.sbert.net/docs/usage/semantic_textual_similarity.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install bert-score"
      ],
      "metadata": {
        "id": "eLoRVYjGHGuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_score import BERTScorer\n",
        "\n",
        "hyps = [\"This is hyp sentence 1\"] # list of output sentences\n",
        "refs = [\"This is ref sentence 1\"] # list of references\n",
        "\n",
        "scorer = BERTScorer(model_type='bert-base-uncased', lang='en')\n",
        "P, R, F1 = scorer.score(hyps, refs)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kChTCXaqHWx9",
        "outputId": "12571ba8-7af5-4037-97ef-b808cb27ab40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.5144, Recall: 0.5965, F1: 0.5465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Referenced from https://www.sbert.net/docs/usage/semantic_textual_similarity.html\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# lists of sentences to compare\n",
        "hyps = [\"This is hyp sentence 1\"]\n",
        "refs = [\"This is ref sentence 1\"]\n",
        "\n",
        "# sentence embedding for both lists\n",
        "embeddings1 = model.encode(hyps, convert_to_tensor=True)\n",
        "embeddings2 = model.encode(refs, convert_to_tensor=True)\n",
        "\n",
        "# cosine-similarities\n",
        "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
        "\n",
        "scores = []\n",
        "\n",
        "for i in range(len(sentences1)):\n",
        "    scores.append(cosine_scores[i][i])\n",
        "\n",
        "ave_cosine_score = sum(scores)/len(scores)\n",
        "print(\"AVERAGE COSINE SCORE {:.5f}\".format(ave_cosine_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H-_vYZqLe8g",
        "outputId": "99d5a20e-7ca6-4287-e37a-f8db52586ea6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AVERAGE COSINE SCORE 0.61768\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}