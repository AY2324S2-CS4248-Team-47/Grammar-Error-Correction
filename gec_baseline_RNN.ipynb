{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH4cdV161Z4T"
      },
      "source": [
        "This implementation of RNN for machine translation was adapted from the following:\n",
        "*   GitHub Repository: [nus-cs4248x](https://github.com/chrisvdweth/nus-cs4248x/blob/master/3-neural-nlp/Section%203.2%20-%20RNN%20Machine%20Translation.ipynb)\n",
        "*  Author: [chrisvdweth](https://github.com/chrisvdweth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx9gadLg98pM"
      },
      "outputs": [],
      "source": [
        "%pip install transformers[sentencepiece] datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNtFHIbnxY3c"
      },
      "outputs": [],
      "source": [
        "%pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YpOJa2kxY3d"
      },
      "outputs": [],
      "source": [
        "%pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cePvcNbXhA7k"
      },
      "outputs": [],
      "source": [
        "%pip install wandb onnx -Uq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdS88fSLXJIH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torchtext\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "# The following src files are retrieved from https://github.com/chrisvdweth/nus-cs4248x/tree/master/3-neural-nlp/src\n",
        "from src.rnn import Encoder, Decoder, RnnAttentionSeq2Seq\n",
        "from src.sampler import BaseDataset, EqualLengthsBatchSampler\n",
        "from src.utils import Dict2Class, get_line_count, plot_attention_weights\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpNQvINyejJr"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "raw_datasets = load_dataset(\"wi_locness\", 'wi')\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "model_checkpoint = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHEa1DNJ1IsR"
      },
      "source": [
        "add speacial tokens to vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUJ1cLa9NGIb"
      },
      "outputs": [],
      "source": [
        "vocab = tokenizer.get_vocab()\n",
        "special_tokens = {'bos_token' : \"<s>\", 'cls_token' : \"<cls>\", 'sep_token' : \"<sep>\"}\n",
        "tokenizer.add_special_tokens(special_tokens)\n",
        "vocab = tokenizer.get_vocab()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22XEFbHIen6l"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = examples['text']\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    labels_out = []\n",
        "    offset_mapping = model_inputs.pop(\"offset_mapping\")\n",
        "    for i in range(len(model_inputs[\"input_ids\"])):\n",
        "        example_idx = i\n",
        "\n",
        "        start_idx = offset_mapping[i][0][0]\n",
        "        end_idx = offset_mapping[i][-2][1]  # last token is <eos>, so we care about second last tok offset\n",
        "\n",
        "        edits = examples[\"edits\"][example_idx]\n",
        "\n",
        "        corrected_text = inputs[example_idx][start_idx:end_idx]\n",
        "\n",
        "        for start, end, correction in reversed(\n",
        "            list(zip(edits[\"start\"], edits[\"end\"], edits[\"text\"]))\n",
        "        ):\n",
        "            if start < start_idx or end > end_idx:\n",
        "                continue\n",
        "            start_offset = start - start_idx  # >= 0\n",
        "            end_offset = end - start_idx\n",
        "            if correction == None:\n",
        "                correction = tokenizer.unk_token\n",
        "            corrected_text = (\n",
        "                corrected_text[:start_offset] + correction + corrected_text[end_offset:]\n",
        "            )\n",
        "\n",
        "        labels_out.append(corrected_text)\n",
        "\n",
        "    labels_out = tokenizer(labels_out, max_length=512, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels_out[\"input_ids\"]\n",
        "\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "29aeabe57aa14b288192732654ec1ddd",
            "18e1c5bdcf1146cd9f2af536006943b1",
            "ed0193626a5a47a1bf983e8fae2bbae0",
            "37aea4ee302947c08a858c5fffda742b",
            "4f1c3d660b604bf3bd74f45b22833dbe",
            "8e76be5b4b9c4d5585ee7c207f136c2f",
            "d78fa8a8c2f74ab595ea3e2b07747cd1",
            "8ad8f9391a2b46fdaab94ec57656552e",
            "30500a5322ee4d3b8fa4719b1e0b1c7a",
            "ca83ecdabab64f8ba194e1878ba6c034",
            "751a54221ef04d60addcd8e6b0f698ca",
            "820c7b486eb647ada9b44e225de8bb82"
          ]
        },
        "id": "BPFRQXDBeqmj",
        "outputId": "c20bf72d-1344-41bb-ddbd-4712ffa3c4b7"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets['train'].column_names\n",
        ")\n",
        "\n",
        "# Train-Test split of 90%-10%\n",
        "dataset_dict = tokenized_datasets[\"train\"].train_test_split(test_size=0.1, seed=0)\n",
        "tokenized_datasets[\"train\"] = dataset_dict[\"train\"]\n",
        "tokenized_datasets[\"test\"] = dataset_dict[\"test\"]\n",
        "\n",
        "X_train = tokenized_datasets[\"train\"][\"input_ids\"]\n",
        "Y_train = tokenized_datasets[\"train\"][\"labels\"]\n",
        "\n",
        "X_test = tokenized_datasets[\"test\"][\"input_ids\"]\n",
        "Y_test = tokenized_datasets[\"test\"][\"labels\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8C5bK5NYtl3"
      },
      "source": [
        "Convert Sequence pairs into list of input and target tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouP08fmZY3oT"
      },
      "outputs": [],
      "source": [
        "len_train = len(X_train)\n",
        "X_train = [ torch.LongTensor(vec) for vec in X_train]\n",
        "Y_train = [ torch.LongTensor(vec) for vec in Y_train]\n",
        "\n",
        "len_validation = len(X_test)\n",
        "X_validation = [ torch.LongTensor(vec) for vec in X_test]\n",
        "Y_validation = [ torch.LongTensor(vec) for vec in Y_test]\n",
        "\n",
        "train_samples = None\n",
        "validation_samples = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilU6r2FYaAET"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "\n",
        "dataset_train = BaseDataset(X_train, Y_train)\n",
        "sampler_train = EqualLengthsBatchSampler(batch_size, X_train, Y_train)\n",
        "loader_train = DataLoader(dataset_train, batch_sampler=sampler_train, shuffle=False, drop_last=False)\n",
        "\n",
        "dataset_test = BaseDataset(X_validation, Y_validation)\n",
        "sampler_test = EqualLengthsBatchSampler(1, X_validation, Y_validation)\n",
        "loader_test = DataLoader(dataset_test, batch_sampler=sampler_test, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZGn7blMaYvP"
      },
      "source": [
        "Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23Se3vmraZtu"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"device\": device,                            # as the decoder also generates sentence it mus be able to move the data to the correct device\n",
        "    \"vocab_size_encoder\": len(vocab),        # the size of the source vocabulary determines the input size of the encoder embedding\n",
        "    \"vocab_size_decoder\": len(vocab),        # the size of the target vocabulary determines the input size of the decoder embedding\n",
        "    \"embed_size\": 300,                           # size of the word embeddings (here the same for encoder and decoder; but not mandatory)\n",
        "    \"rnn_cell\": \"LSTM\",                          # in practice GRU or LSTM will always outperform RNN\n",
        "    \"rnn_hidden_size\": 512,                      # size of the hidden state\n",
        "    \"rnn_num_layers\": 2,                         # 1 or 2 layers are most common; more rarely sees any benefit\n",
        "    \"rnn_dropout\": 0.2,                          # only relevant if rnn_num_layers > 1\n",
        "    \"rnn_encoder_bidirectional\": True,           # The encoder can be bidirectional; the decoder can not\n",
        "    \"linear_hidden_sizes\": [1024, 2048],         # list of sizes of subsequent hidden layers; can be [] (empty); only relevant for the decoder\n",
        "    \"linear_dropout\": 0.2,                       # if hidden linear layers are used, we can also include Dropout; only relevant for the decoder\n",
        "    \"attention\": \"DOT\",                          # Specify if attention should be used; only \"DOT\" supported; None if no attention\n",
        "    \"teacher_forcing_prob\": 0.5,                 # Probability of using Teacher Forcing during training by the decoder\n",
        "    \"special_token_unk\": vocab['<unk>'],     # Index of special token <UNK>\n",
        "    \"special_token_sos\": vocab['<s>'],     # Index of special token <SOS>\n",
        "    \"special_token_eos\": vocab['</s>'],     # Index of special token <EOS>\n",
        "    \"clip\": 1.0                                  # Clipping value to limit gradients to prevent exploding gradients\n",
        "}\n",
        "\n",
        "# wandb.init(project='gec-baseline-lstm-rnn', config=params)\n",
        "\n",
        "params = Dict2Class(params)\n",
        "\n",
        "\n",
        "model = RnnAttentionSeq2Seq(params, nn.CrossEntropyLoss()).to(device)\n",
        "encoder_optimizer = optim.Adam(model.encoder.parameters(), lr=0.0005)\n",
        "decoder_optimizer = optim.Adam(model.decoder.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a15BqjS7adwn"
      },
      "outputs": [],
      "source": [
        "def train_batch(model, encoder_optimizer, decoder_optimizer, X, Y):\n",
        "    batch_size, num_steps = X.shape\n",
        "\n",
        "    loss = model(X, Y)\n",
        "\n",
        "    # Backpropagation\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.encoder.parameters(), model.encoder.params.clip)\n",
        "    torch.nn.utils.clip_grad_norm_(model.decoder.parameters(), model.decoder.params.clip)\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / (num_steps)\n",
        "\n",
        "def train(model, loader, encoder_optimizer, decoder_optimizer, num_epochs, verbose=False):\n",
        "    # wandb.watch(model, log=\"all\", log_freq=10)\n",
        "    # Set model to \"train\" mode\n",
        "    model.train()\n",
        "\n",
        "    print(\"Total Training Time (total number of epochs: {})\".format(num_epochs))\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "\n",
        "        # Initialize epoch loss (cummulative loss fo all batchs)\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        with tqdm(total=len(loader)) as progress_bar:\n",
        "\n",
        "            for X_batch, Y_batch in loader:\n",
        "                batch_size, seq_len = X_batch.shape[0], X_batch.shape[1]\n",
        "\n",
        "                # Add EOS token to all sequences in that batch\n",
        "                eos = torch.LongTensor([model.encoder.params.special_token_eos]*batch_size)\n",
        "                X_batch = torch.cat((X_batch, eos.reshape(-1, 1)), axis=1)\n",
        "                Y_batch = torch.cat((Y_batch, eos.reshape(-1, 1)), axis=1)\n",
        "\n",
        "                # Move the batch to the correct device\n",
        "                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "\n",
        "                # Train batch and get batch loss\n",
        "                batch_loss = train_batch(model, encoder_optimizer, decoder_optimizer, X_batch, Y_batch)\n",
        "\n",
        "                # Update epoch loss given als batch loss\n",
        "                epoch_loss += batch_loss\n",
        "\n",
        "                # Update progress bar\n",
        "                progress_bar.update(batch_size)\n",
        "\n",
        "        if verbose is True:\n",
        "            print(\"Loss:\\t{:.3f} (epoch {})\".format(epoch_loss, epoch))\n",
        "            epoch_loss_value = round(epoch_loss, 5)\n",
        "            # wandb.log({\"epoch\": epoch, \"loss\": epoch_loss_value})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n5pTR3k02zk"
      },
      "outputs": [],
      "source": [
        "num_epochs = 50\n",
        "\n",
        "train(model, loader_train, encoder_optimizer, decoder_optimizer, num_epochs, verbose=True)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xKcd_3faqp2"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "action = \"save\"\n",
        "#action = \"load\"\n",
        "#action = \"none\"\n",
        "\n",
        "if action == \"save\":\n",
        "    torch.save(model.state_dict(), 'wi-rnn-new.pt')\n",
        "elif action == 'load':\n",
        "    model = RnnAttentionSeq2Seq(params, nn.CrossEntropyLoss()).to(device)\n",
        "    model.load_state_dict(torch.load('wi-rnn-new.pt'))\n",
        "else:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCI8WzzaazPC"
      },
      "source": [
        "Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuTZVlp3a1Iv"
      },
      "outputs": [],
      "source": [
        "def translate(model, inputs, max_len=512):\n",
        "    # Encode input sequence/sentence\n",
        "    encoder_outputs, encoder_hidden = model.encoder(inputs)\n",
        "    # Translate input but generating/predicting the output sequence/sentence\n",
        "    decoded_indices, attention_weights = model.decoder.generate(encoder_hidden, encoder_outputs, max_len=max_len)\n",
        "    # Return the translation + the attention weights\n",
        "    return decoded_indices, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0um6kMQ02zm"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saMbXhRCbAJL"
      },
      "outputs": [],
      "source": [
        "for idx, (inputs, targets) in enumerate(loader_test):\n",
        "    # The input is the first sequence\n",
        "    inputs = inputs[0:1].to(device)\n",
        "    # Decode input sequence of indices to sequences of word/tokens\n",
        "    src_labels = tokenizer.decode(inputs[0].cpu().numpy().tolist())\n",
        "\n",
        "    # Translate input sequence into predicted target sequence\n",
        "    decoded_indices, attention_weights = translate(model, inputs)\n",
        "\n",
        "    # Decode target sequence of indices to sequences of word/tokens\n",
        "    tgt_labels = tokenizer.decode(decoded_indices)\n",
        "\n",
        "\n",
        "    print((src_labels))\n",
        "    print()\n",
        "    print((tgt_labels))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18e1c5bdcf1146cd9f2af536006943b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e76be5b4b9c4d5585ee7c207f136c2f",
            "placeholder": "​",
            "style": "IPY_MODEL_d78fa8a8c2f74ab595ea3e2b07747cd1",
            "value": "Map: 100%"
          }
        },
        "29aeabe57aa14b288192732654ec1ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18e1c5bdcf1146cd9f2af536006943b1",
              "IPY_MODEL_ed0193626a5a47a1bf983e8fae2bbae0",
              "IPY_MODEL_37aea4ee302947c08a858c5fffda742b"
            ],
            "layout": "IPY_MODEL_4f1c3d660b604bf3bd74f45b22833dbe"
          }
        },
        "30500a5322ee4d3b8fa4719b1e0b1c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37aea4ee302947c08a858c5fffda742b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca83ecdabab64f8ba194e1878ba6c034",
            "placeholder": "​",
            "style": "IPY_MODEL_751a54221ef04d60addcd8e6b0f698ca",
            "value": " 3000/3000 [00:06&lt;00:00, 455.09 examples/s]"
          }
        },
        "4f1c3d660b604bf3bd74f45b22833dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "751a54221ef04d60addcd8e6b0f698ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ad8f9391a2b46fdaab94ec57656552e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e76be5b4b9c4d5585ee7c207f136c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca83ecdabab64f8ba194e1878ba6c034": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78fa8a8c2f74ab595ea3e2b07747cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed0193626a5a47a1bf983e8fae2bbae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad8f9391a2b46fdaab94ec57656552e",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30500a5322ee4d3b8fa4719b1e0b1c7a",
            "value": 3000
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
