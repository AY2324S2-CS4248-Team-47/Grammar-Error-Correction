{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx9gadLg98pM",
        "outputId": "a3bf121c-d7fe-4cf3-9bf2-5bf89858655a"
      },
      "outputs": [],
      "source": [
        "%pip install transformers[sentencepiece] datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNtFHIbnxY3c",
        "outputId": "3e96a59f-2fea-4349-e4e0-fc3650a89256"
      },
      "outputs": [],
      "source": [
        "%pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YpOJa2kxY3d",
        "outputId": "3d669232-1f4e-44e6-92a6-ecdcba83fe52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cePvcNbXhA7k",
        "outputId": "661af03c-5f01-4af3-de50-849406312afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install wandb onnx -Uq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdS88fSLXJIH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torchtext\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "from src.rnn import Encoder, Decoder, RnnAttentionSeq2Seq\n",
        "from src.sampler import BaseDataset, EqualLengthsBatchSampler\n",
        "from src.utils import Dict2Class, get_line_count, plot_attention_weights\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpNQvINyejJr"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "raw_datasets = load_dataset(\"wi_locness\", 'wi')\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "model_checkpoint = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22XEFbHIen6l"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = examples['text']\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    labels_out = []\n",
        "    offset_mapping = model_inputs.pop(\"offset_mapping\")\n",
        "    for i in range(len(model_inputs[\"input_ids\"])):\n",
        "        example_idx = i\n",
        "\n",
        "        start_idx = offset_mapping[i][0][0]\n",
        "        end_idx = offset_mapping[i][-2][1]  # last token is <eos>, so we care about second last tok offset\n",
        "\n",
        "        edits = examples[\"edits\"][example_idx]\n",
        "\n",
        "        corrected_text = inputs[example_idx][start_idx:end_idx]\n",
        "\n",
        "        for start, end, correction in reversed(\n",
        "            list(zip(edits[\"start\"], edits[\"end\"], edits[\"text\"]))\n",
        "        ):\n",
        "            if start < start_idx or end > end_idx:\n",
        "                continue\n",
        "            start_offset = start - start_idx  # >= 0\n",
        "            end_offset = end - start_idx\n",
        "            if correction == None:\n",
        "                correction = tokenizer.unk_token\n",
        "            corrected_text = (\n",
        "                corrected_text[:start_offset] + correction + corrected_text[end_offset:]\n",
        "            )\n",
        "\n",
        "        labels_out.append(corrected_text)\n",
        "\n",
        "    labels_out = tokenizer(labels_out, max_length=512, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels_out[\"input_ids\"]\n",
        "\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cd35b484f9084ec0b6d690f7a4ad2463",
            "1566a39b22de427192f7660c6d0902bb",
            "e0091a27b90c4e3ab75f38a0c3ea4afa",
            "0e09659b00b94be6852a25275dcb3d1a",
            "5a9475f602bf4487a0429ede0064c6d6",
            "fdf57322b901404191a55fc1921f5f1f",
            "9441586eaa9e48e896cdc9629c33f63d",
            "9f75f8f8668c4124927c8d62c7dea2cd",
            "ff1f8fcae7cd43ac89eee00ce81b3e6f",
            "b09127a0ca974b33904240eab8b5960e",
            "2d33a774753847e0b68ffa00919686cc"
          ]
        },
        "id": "BPFRQXDBeqmj",
        "outputId": "397ee5ed-ba87-4abc-b57f-ff120b2dfe04"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd35b484f9084ec0b6d690f7a4ad2463",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets['train'].column_names\n",
        ")\n",
        "\n",
        "# Train-Test split of 90%-10%\n",
        "dataset_dict = tokenized_datasets[\"train\"].train_test_split(test_size=0.1, seed=0)\n",
        "tokenized_datasets[\"train\"] = dataset_dict[\"train\"]\n",
        "tokenized_datasets[\"test\"] = dataset_dict[\"test\"]\n",
        "\n",
        "X_train = tokenized_datasets[\"train\"][\"input_ids\"]\n",
        "Y_train = tokenized_datasets[\"train\"][\"labels\"]\n",
        "\n",
        "X_test = tokenized_datasets[\"test\"][\"input_ids\"]\n",
        "Y_test = tokenized_datasets[\"test\"][\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVt2wNrMe9b7"
      },
      "outputs": [],
      "source": [
        "# print(tokenizer.decode(X_train[0]))\n",
        "# print(tokenizer.decode(Y_train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9XnJ2Uae1CL",
        "outputId": "93ee06bb-7687-4962-8534-31035b13958a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"I've been start jogging for five years. It is the way I can unwind because my study it's stressful. It gives me a sense of achievement, for these reasons I would like to do every day. I love jogging because it's a way to stay outdor immersed in nature. I think there are not negative side in doing jogging. I have been really on skiing since I was a baby. My mother make me start. Since then every year i go in north Italy to practice. I fell relaxed staying alon near montains and snow.</s>\", \"what I usually do in my free time. I really like reading many kinds of books, magazine, etc.when the weather is bad, I love sitting in my favorite armchaire,near the fire place and reading.I enioy to hear the rain while I am reading at home... Howhever I like very much walking too.When the weather is good I often go out with my friend for a walk in the countryside or do shopping. I also love watching films at the cinema or on tv.I prefer comedy and romance, but I like triller and drama too. At least I enioy to take care on my garden, where there are many flowerbeds with a lot of kinds of flowers. Dear Laura, I am glad to hear you and know you have bought a new computer game. Actually I don't like very much the computer games, because in my opinion they are so boring!I also think these games get a sort of dependency, like the alcohol or the drugs, so they can be very dangerous! I really prefer doing other kind of things on my computer, like to surf the Internet, to study English, etc. For example I use my computer to prepare exercises for my students or to look for funny and useful laboratory's experiences of chemistry. See you soon. Kisses. Sara A terrible holiday Last year I decided to go on holiday with my friends. We like very much the sea, so we looked to rent a little cottage on August at a lovely place in Sardegna. We arrived at the island in the morning, after a long journey on a ferryboat. Then we got on a bus to arrive at the house which we had rented.The cottage was really fine, with a fantastic view of the beach.I looked forward to go on the beach and to swim in that wonderful wather.But the lucky wasn't with me! In fact I was ill all the time and I only could look the sea through the window of my room! Dear Jeanny, I am always glad to receive your letter! My favourite TV programme is Quark. This is a documentary about the science. I like watching it because in this programme I can get a lot of information. For example I can know about the Big Bang, the origin of the universe, it's fascinating! I can also look about the astronomy, the</s>\", 'Alison read the note,smiled,and immediatly put on her coat. Alison put on her coat,close the door and went to his parents house by car.She went to his parents house because they sent her an email that said that his father is okay after the oparation. When alison knock on his parents door she noticed that there were many people in her parents house, a man open the front door.When she entered the house,a man was looking at her with a bad face,when suddenly this man shot with a gun to Alison father. Alison left the house very scared,it was a dream. </s>', \"Many people all around the world love football.Football is such a beauty sport because it is really a fun in a lot of many ways.Football is my favourite sport and I think it is never going away in my life. I love football because there's a lot of enjoyment in it.I play football for Waitakere college school first eleven as a deffender and I enjoy playing that position because it is easy for me to play. I used to dream of playing for barcelona and because barcelona has good players I like I,for example Lionel Messi.Because where I was born there wasn't any chance for me to practise football so I can become really good like other players.But even though I will never get a chance of playing for my dream team I still enjoy playing football.I can play with people who are good and I still have fun. I advise young kids to train hard and play football because there's a lot of fun.Once you start playing football, on a young age you get really better at football.</s>\", 'When I was a little girl I used to play volleyboll and I really liked that. One day I had a surprise, I have met a teacher and he invited me to tranee in a huge gym in a team. I started to think that was born for that sport. I worked too hard, but enjoe playing really. Sundully happanned sonething, I need to work to play my studuies in the High school, so the life changes anyway, I needed to stop my favourite sport, because I should need to study in that moment it was more important for me. Today I do not play volleyboll anymore, but I really enjoy dancing, now I can say that it is my favourite, it is all of.</s>']\n",
            "[\"I've been jogging for five years. It is the way I can unwind, because my studies are stressful. It gives me a sense of achievement. For these reasons, I would like to it do every day. I love jogging because it's a way to stay outdoors, immersed in nature. I think there are no negative sides to jogging. I have been really into skiing since I was a baby. My mother made me start. Since then, every year, I go to northern Italy to practice. I fell relaxed being alone near mountains and snow.</s>\", \"What I usually do in my free time. I really like reading many kinds of books, magazines, etc. When the weather is bad, I love sitting in my favorite armchair, near the fire place and reading. I enjoy hearing the rain while I am reading at home. However, I like walking very much, too. When the weather is good, I often go out with my friend for a walk in the countryside or go shopping. I also love watching films at the cinema or on TV. I prefer comedy and romance, but I like thrillers and drama too. Finally, I enjoy taking care of my garden, where there are many flowerbeds with a lot of different kinds of flowers. Dear Laura, I am glad to hear from you and know you have bought a new computer game. Actually, I don't like computer games very much, because, in my opinion, they are so boring! I also think these games create a sort of dependency, like alcohol or drugs, so they can be very dangerous! I really prefer doing other kinds of things on my computer, like surfing the Internet, studying English, etc. For example, I use my computer to prepare exercises for my students or to look for funny and useful laboratory experiments in chemistry. See you soon. Kisses. Sara A terrible holiday Last year I decided to go on holiday with my friends. We like the sea very much, so we looked to rent a little cottage in August in a lovely place in Sardinia. We arrived on the island in the morning, after a long journey on a ferryboat. Then we got on a bus to go to the house which we had rented. The cottage was really great, with a fantastic view of the beach. I was looking forward to going to the beach and swimming in that wonderful water. But luck wasn't with me! In fact, I was ill all the time and I could only look at the sea through the window of my room! Dear Jeanny, I am always glad to receive your letters! My favourite TV programme is Quark. This is a documentary about science. I like watching it because I can get a lot of information from this programme. For example, I can learn about the Big Bang, or the origin of the universe. It's fascinating! I can also learn about astronomy, </s>\", \"Alison read the note, smiled, and immediately put on her coat. Alison put on her coat, closed the door and went to her parents' house by car. She went to her parents' house because they sent her an email that said that her father was okay after the operation. When Alison knocked on her parents' door she noticed that there were many people in her parents' house, a man opened the front door. When she entered the house, a man was looking at her with a <unk> face, when suddenly this man shot Alison's father with a gun. Alison left the house very scared; it was a dream. </s>\", \"Many people all around the world love football. Football is such a beautiful sport because it is really fun in a lot of ways. Football is my favourite sport and I think it will always be in my life. I love football because there's a lot of enjoyment in it. I play football for Waitakere college school first eleven as a defender and I enjoy playing in that position because it is easy for me to play. I used to dream of playing for Barcelona because Barcelona has good players I like. For example, Lionel Messi. Where I was born there wasn't any chance for me to practise football so I could become really good like other players. But even though I will never get a chance of playing for my dream team, I still enjoy playing football. I can play with people who are good and I still have fun. I advise young kids to train hard and play football because it's a lot of fun. If you start playing football at a young age, you really get better at football.</s>\", 'When I was a little girl I used to play volleyball and I really liked that. One day, I had a surprise. I met a teacher and he invited me to train in a huge gym in a team. I started to think that I was born for that sport. I worked so hard, but really enjoyed playing. Suddenly something happened. I needed to work to <unk> my studies in high school, so life changes anyway. I needed to stop my favourite sport, because I needed to study at that time. It was more important to me. Today I do not play volleyball anymore, but I really enjoy dancing. Now I can say that it is my favourite, <unk></s>']\n"
          ]
        }
      ],
      "source": [
        "# get dataset sequences\n",
        "text_train = []\n",
        "corrected_train = []\n",
        "for idx in range(len(X_train)):\n",
        "  text_train.append(tokenizer.decode(X_train[idx]))\n",
        "  corrected_train.append(tokenizer.decode(Y_train[idx]))\n",
        "\n",
        "text_validation = []\n",
        "corrected_validation = []\n",
        "for idx in range(len(X_test)):\n",
        "  text_validation.append(tokenizer.decode(X_test[idx]))\n",
        "  corrected_validation.append(tokenizer.decode(Y_test[idx]))\n",
        "print(text_train)\n",
        "print(corrected_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZLIXHwR4abR"
      },
      "source": [
        "Create Vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjJHLYa74cMF",
        "outputId": "791a6c19-302f-4865-ab8d-7fa22ebb74fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 523.75it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 713.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all vocab in  436\n",
            "all vocab out  402\n",
            "Size of IN vocabulary: 441\n",
            "Size of OUT vocabulary: 406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter, OrderedDict\n",
        "\n",
        "in_token_counter = Counter()\n",
        "out_token_counter = Counter()\n",
        "num_samples = len(text_train)\n",
        "\n",
        "# vocab for erroneous\n",
        "with tqdm(total=num_samples) as t:\n",
        "  for line in text_train:\n",
        "    line = line.strip()\n",
        "    try:\n",
        "      for token in tokenizer.tokenize(line):\n",
        "        in_token_counter[token] += 1\n",
        "    except:\n",
        "      pass\n",
        "    finally:\n",
        "      t.update(1)\n",
        "\n",
        "# vocab for corrected\n",
        "with tqdm(total=num_samples) as t2:\n",
        "  for line in corrected_train:\n",
        "    line = line.strip()\n",
        "    try:\n",
        "      for token in tokenizer.tokenize(line):\n",
        "        out_token_counter[token] += 1\n",
        "    except:\n",
        "      pass\n",
        "    finally:\n",
        "      t2.update(1)\n",
        "\n",
        "# sort word freqs and covert ot OrderedDict\n",
        "in_token_counter_sorted = sorted(in_token_counter.items(), key=lambda x: x[1], reverse=True)\n",
        "out_token_counter_sorted = sorted(out_token_counter.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"all vocab in \", len(in_token_counter))\n",
        "print(\"all vocab out \", len(out_token_counter))\n",
        "in_token_ordered_dict = OrderedDict(in_token_counter_sorted[:len(in_token_counter)])\n",
        "out_token_ordered_dict = OrderedDict(out_token_counter_sorted[:len(out_token_counter)])\n",
        "\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "UNK_TOKEN = \"<unk>\"\n",
        "SOS_TOKEN = \"<s>\"\n",
        "EOS_TOKEN = \"</s>\"\n",
        "CLS_TOKEN = \"<cls>\"\n",
        "SEP_TOKEN = \"<sep>\"\n",
        "\n",
        "SPECIALS = [PAD_TOKEN, UNK_TOKEN, SOS_TOKEN, EOS_TOKEN, CLS_TOKEN, SEP_TOKEN]\n",
        "\n",
        "vocab_in = vocab(in_token_ordered_dict, specials=SPECIALS)\n",
        "vocab_out = vocab(out_token_ordered_dict, specials=SPECIALS)\n",
        "\n",
        "vocab_in.set_default_index(vocab_in[UNK_TOKEN])\n",
        "vocab_out.set_default_index(vocab_out[UNK_TOKEN])\n",
        "\n",
        "print(\"Size of IN vocabulary: {}\".format(len(vocab_in)))\n",
        "print(\"Size of OUT vocabulary: {}\".format(len(vocab_out)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDLvcnMk6mM8"
      },
      "outputs": [],
      "source": [
        "# save vocab files\n",
        "vocab_in_file_name = 'err-wi-train.vocab'\n",
        "vocab_out_file_name = 'cor-wi-train.vocab'\n",
        "\n",
        "torch.save(vocab_in, vocab_in_file_name)\n",
        "torch.save(vocab_out, vocab_out_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOP-rCrx-Lk5",
        "outputId": "694d89dc-f782-442c-d666-2c0078daa102"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 456.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "([6, 23, 162, 93, 68, 7, 50, 69, 70, 19, 163, 164, 8, 94, 17, 10, 95, 6, 28, 165, 166, 20, 14, 71, 21, 23, 26, 167, 8, 94, 168, 33, 7, 11, 169, 15, 170, 9, 19, 96, 171, 6, 172, 22, 12, 51, 97, 98, 8, 6, 42, 7, 50, 69, 70, 20, 21, 23, 26, 7, 11, 95, 12, 173, 99, 52, 174, 175, 176, 13, 177, 8, 6, 53, 37, 54, 100, 178, 179, 13, 101, 7, 50, 69, 70, 8, 6, 55, 93, 24, 18, 180, 181, 6, 27, 7, 11, 182, 8, 102, 183, 184, 33, 68, 8, 185, 186, 97, 103, 7, 56, 57, 13, 187, 188, 12, 189, 8, 6, 190, 191, 192, 193, 72, 194, 195, 196, 16, 197, 8, 3], [7, 17, 149, 85, 9, 60, 61, 62, 21, 150, 151, 6, 51, 22, 12, 86, 7, 31, 152, 153, 8, 18, 14, 87, 39, 154, 6, 51, 155, 32, 9, 10, 156, 15, 157, 6, 52, 88, 158, 8, 7, 159, 19, 11, 23, 63, 89, 90, 6, 7, 40, 9, 60, 61, 62, 18, 23, 17, 28, 9, 10, 86, 11, 160, 161, 8, 162, 163, 13, 164, 6, 7, 53, 41, 39, 165, 166, 167, 11, 9, 60, 61, 62, 6, 7, 64, 85, 24, 168, 169, 170, 7, 20, 9, 10, 171, 6, 91, 172, 173, 32, 92, 6, 174, 175, 8, 89, 93, 8, 7, 42, 11, 176, 177, 11, 178, 6, 7, 179, 180, 181, 182, 94, 183, 16, 184, 6, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "100%|██████████| 300/300 [00:00<00:00, 657.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "300\n",
            "([1, 83, 1, 85, 14, 63, 67, 9, 1, 395, 249, 8, 6, 42, 1, 9, 394, 6, 1, 36, 1, 20, 21, 17, 158, 12, 1, 7, 11, 1, 12, 36, 1, 13, 1, 8, 6, 22, 1, 20, 21, 17, 1, 15, 10, 1, 67, 8, 1, 23, 26, 1, 85, 10, 1, 15, 41, 1, 8, 6, 53, 41, 1, 1, 33, 12, 249, 1, 8, 1, 1, 1, 12, 36, 1, 67, 9, 1, 17, 14, 375, 1, 8, 94, 17, 342, 382, 67, 12, 36, 19, 1, 396, 146, 36, 390, 67, 1, 8, 1, 9, 239, 1, 26, 28, 1, 16, 120, 10, 1, 1, 8, 1, 54, 10, 1, 85, 1, 9, 14, 63, 67, 8, 3], [373, 76, 1, 77, 14, 57, 59, 8, 23, 135, 106, 1, 6, 7, 40, 1, 8, 368, 7, 1, 37, 1, 18, 23, 22, 147, 11, 1, 9, 10, 1, 11, 37, 1, 13, 1, 6, 7, 19, 1, 18, 23, 22, 1, 15, 12, 1, 1, 6, 1, 17, 28, 1, 77, 12, 1, 15, 38, 1, 6, 7, 53, 38, 1, 1, 32, 11, 106, 1, 6, 373, 1, 1, 11, 37, 1, 59, 8, 1, 22, 14, 353, 1, 6, 51, 22, 324, 358, 59, 11, 37, 21, 1, 370, 359, 369, 1, 364, 59, 1, 6, 1, 8, 227, 1, 28, 31, 1, 16, 225, 12, 1, 1, 6, 304, 22, 9, 10, 1, 77, 1, 8, 14, 57, 59, 6, 3])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# vectorize seqs\n",
        "\n",
        "train_samples = []\n",
        "\n",
        "with tqdm(total=num_samples) as t:\n",
        "  for idx,line in enumerate(text_train):\n",
        "    err_line = line.strip()\n",
        "    cor_line = corrected_train[idx].strip()\n",
        "    try:\n",
        "      err_vec = vocab_in.lookup_indices(tokenizer.tokenize(err_line))\n",
        "      cor_vec = vocab_out.lookup_indices(tokenizer.tokenize(cor_line))\n",
        "      train_samples.append((err_vec, cor_vec))\n",
        "    except:\n",
        "      pass\n",
        "    finally:\n",
        "      t.update(1)\n",
        "\n",
        "print(len(train_samples))\n",
        "print(train_samples[0])\n",
        "\n",
        "validation_samples = []\n",
        "\n",
        "with tqdm(total=len(text_validation)) as t:\n",
        "  for idx,line in enumerate(text_validation):\n",
        "    err_line = line.strip()\n",
        "    cor_line = corrected_validation[idx].strip()\n",
        "    try:\n",
        "      err_vec = vocab_in.lookup_indices(tokenizer.tokenize(err_line))\n",
        "      cor_vec = vocab_out.lookup_indices(tokenizer.tokenize(cor_line))\n",
        "      validation_samples.append((err_vec, cor_vec))\n",
        "    except:\n",
        "      pass\n",
        "    finally:\n",
        "      t.update(1)\n",
        "print(len(validation_samples))\n",
        "print(validation_samples[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8C5bK5NYtl3"
      },
      "source": [
        "Convert Sequence pairs into list of input and target tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouP08fmZY3oT"
      },
      "outputs": [],
      "source": [
        "len_train = len(train_samples)\n",
        "X_train = [ torch.LongTensor(err) for (err, _) in train_samples[:len_train] ]\n",
        "Y_train = [ torch.LongTensor(cor) for (_, cor) in train_samples[:len_train] ]\n",
        "\n",
        "len_validation = len(validation_samples)\n",
        "X_validation = [ torch.LongTensor(err) for (err, _) in validation_samples[:len_validation] ]\n",
        "Y_validation = [ torch.LongTensor(cor) for (_, cor) in validation_samples[:len_validation] ]\n",
        "\n",
        "train_samples = None\n",
        "validation_samples = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilU6r2FYaAET"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "\n",
        "dataset_train = BaseDataset(X_train, Y_train)\n",
        "sampler_train = EqualLengthsBatchSampler(batch_size, X_train, Y_train)\n",
        "loader_train = DataLoader(dataset_train, batch_sampler=sampler_train, shuffle=False, drop_last=False)\n",
        "\n",
        "dataset_test = BaseDataset(X_validation, Y_validation)\n",
        "sampler_test = EqualLengthsBatchSampler(1, X_validation, Y_validation)\n",
        "loader_test = DataLoader(dataset_test, batch_sampler=sampler_test, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZGn7blMaYvP"
      },
      "source": [
        "Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "6HesXCczg8Lp",
        "outputId": "7c105c13-3113-4da7-81cb-0acbfdfdb292"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlethiciars\u001b[0m (\u001b[33may2324s2-cs4248-team-47\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23Se3vmraZtu"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"device\": device,                            # as the decoder also generates sentence it mus be able to move the data to the correct device\n",
        "    \"vocab_size_encoder\": len(vocab_in),        # the size of the source vocabulary determines the input size of the encoder embedding\n",
        "    \"vocab_size_decoder\": len(vocab_out),        # the size of the target vocabulary determines the input size of the decoder embedding\n",
        "    \"embed_size\": 300,                           # size of the word embeddings (here the same for encoder and decoder; but not mandatory)\n",
        "    \"rnn_cell\": \"GRU\",                          # in practice GRU or LSTM will always outperform RNN\n",
        "    \"rnn_hidden_size\": 512,                      # size of the hidden state\n",
        "    \"rnn_num_layers\": 2,                         # 1 or 2 layers are most common; more rarely sees any benefit\n",
        "    \"rnn_dropout\": 0.2,                          # only relevant if rnn_num_layers > 1\n",
        "    \"rnn_encoder_bidirectional\": True,           # The encoder can be bidirectional; the decoder can not\n",
        "    \"linear_hidden_sizes\": [1024, 2048],         # list of sizes of subsequent hidden layers; can be [] (empty); only relevant for the decoder\n",
        "    \"linear_dropout\": 0.2,                       # if hidden linear layers are used, we can also include Dropout; only relevant for the decoder\n",
        "    \"attention\": \"DOT\",                          # Specify if attention should be used; only \"DOT\" supported; None if no attention\n",
        "    \"teacher_forcing_prob\": 0.5,                 # Probability of using Teacher Forcing during training by the decoder\n",
        "    \"special_token_unk\": vocab_out['<unk>'],     # Index of special token <UNK>\n",
        "    \"special_token_sos\": vocab_out['<s>'],     # Index of special token <SOS>\n",
        "    \"special_token_eos\": vocab_out['</s>'],     # Index of special token <EOS>\n",
        "    \"clip\": 1.0                                  # Clipping value to limit gradients to prevent exploding gradients\n",
        "}\n",
        "\n",
        "wandb.init(project='gec-baseline-gru-rnn', config=params)\n",
        "\n",
        "params = Dict2Class(params)\n",
        "# Create model (incl. the definition of the loss function)\n",
        "model = RnnAttentionSeq2Seq(params, nn.CrossEntropyLoss()).to(device)\n",
        "# Define optimizers (for encoder and decoder)\n",
        "encoder_optimizer = optim.Adam(model.encoder.parameters(), lr=0.0005)\n",
        "decoder_optimizer = optim.Adam(model.decoder.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a15BqjS7adwn"
      },
      "outputs": [],
      "source": [
        "def train_batch(model, encoder_optimizer, decoder_optimizer, X, Y):\n",
        "    batch_size, num_steps = X.shape\n",
        "\n",
        "    loss = model(X, Y)\n",
        "\n",
        "    # Backpropagation\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.encoder.parameters(), model.encoder.params.clip)\n",
        "    torch.nn.utils.clip_grad_norm_(model.decoder.parameters(), model.decoder.params.clip)\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / (num_steps)\n",
        "\n",
        "def train(model, loader, encoder_optimizer, decoder_optimizer, num_epochs, verbose=False):\n",
        "    wandb.watch(model, log=\"all\", log_freq=10)\n",
        "    # Set model to \"train\" mode\n",
        "    model.train()\n",
        "\n",
        "    print(\"Total Training Time (total number of epochs: {})\".format(num_epochs))\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "\n",
        "        # Initialize epoch loss (cummulative loss fo all batchs)\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        with tqdm(total=len(loader)) as progress_bar:\n",
        "\n",
        "            for X_batch, Y_batch in loader:\n",
        "                batch_size, seq_len = X_batch.shape[0], X_batch.shape[1]\n",
        "\n",
        "                # Add EOS token to all sequences in that batch\n",
        "                eos = torch.LongTensor([model.encoder.params.special_token_eos]*batch_size)\n",
        "                X_batch = torch.cat((X_batch, eos.reshape(-1, 1)), axis=1)\n",
        "                Y_batch = torch.cat((Y_batch, eos.reshape(-1, 1)), axis=1)\n",
        "\n",
        "                # Move the batch to the correct device\n",
        "                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "\n",
        "                # Train batch and get batch loss\n",
        "                batch_loss = train_batch(model, encoder_optimizer, decoder_optimizer, X_batch, Y_batch)\n",
        "\n",
        "                # Update epoch loss given als batch loss\n",
        "                epoch_loss += batch_loss\n",
        "\n",
        "                # Update progress bar\n",
        "                progress_bar.update(batch_size)\n",
        "\n",
        "        if verbose is True:\n",
        "            print(\"Loss:\\t{:.3f} (epoch {})\".format(epoch_loss, epoch))\n",
        "            epoch_loss_value = round(epoch_loss, 5)\n",
        "            wandb.log({\"epoch\": epoch, \"loss\": epoch_loss_value})\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "          filename = f\"gru_{epoch}.pt\"\n",
        "          torch.save(model.state_dict(), filename)\n",
        "          print(\"saved gru at epoch = \", epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWe3buOvanyR",
        "outputId": "d68660ef-a43f-44db-fc85-e5bc48cccaf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Training Time (total number of epochs: 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:06<00:00,  1.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss:\t27.282 (epoch 1)\n",
            "Number of parameters: 28745258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "\n",
        "train(model, loader_train, encoder_optimizer, decoder_optimizer, num_epochs, verbose=True)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xKcd_3faqp2"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "action = \"save\"\n",
        "#action = \"load\"\n",
        "#action = \"none\"\n",
        "\n",
        "if action == \"save\":\n",
        "    torch.save(model.state_dict(), 'wi-rnn.pt')\n",
        "elif action == 'load':\n",
        "    model = RnnAttentionSeq2Seq(params, nn.CrossEntropyLoss()).to(device)\n",
        "    model.load_state_dict(torch.load('wi-rnn.pt'))\n",
        "else:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJhcb5Trn39p"
      },
      "outputs": [],
      "source": [
        "# import torch.onnx\n",
        "# torch.onnx.export(model, images, \"model.onnx\")\n",
        "# wandb.save(\"model.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCI8WzzaazPC"
      },
      "source": [
        "Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuTZVlp3a1Iv"
      },
      "outputs": [],
      "source": [
        "def translate(model, inputs, max_len=100):\n",
        "    # Encode input sequence/sentence\n",
        "    encoder_outputs, encoder_hidden = model.encoder(inputs)\n",
        "    # Translate input but generating/predicting the output sequence/sentence\n",
        "    decoded_indices, attention_weights = model.decoder.generate(encoder_hidden, encoder_outputs, max_len=max_len)\n",
        "    # Return the translation + the attention weights\n",
        "    return decoded_indices, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "saMbXhRCbAJL",
        "outputId": "54a6b523-0e35-418e-e3d8-fcd885afb7e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▁The ▁topic ▁itself ▁explaining ▁the ▁uncertainty ▁of ▁public ▁transport ▁in ▁our ▁country . This ▁conclusion ▁become ▁more ▁prominent ▁ if ▁we ▁look ▁into ▁the ▁data ▁of ▁the ▁car ▁companies ▁and ▁exponential ▁growth ▁in ▁their ▁sales ▁figure ▁and ▁with ▁low ▁budget ▁private ▁cars ▁in ▁picture , ▁scenario ▁ d d <unk> ically ▁changed ▁in ▁past ▁10 ▁years ▁ </s>\n",
            "\n",
            "▁The ▁topic ▁becomes ▁admitted ▁the ▁intention ▁of ▁public ▁transport ▁in ▁our ▁country . ▁This ▁is ▁more ▁important ▁ <unk> ▁ . ▁ ▁ ▁to ▁ ▁the ▁the ▁the ▁the ▁the ▁the ▁and ▁to ▁and ▁and ▁and ▁to ▁and ▁to , , ▁in , , ▁in ▁the . ▁ . ▁the . .\n"
          ]
        }
      ],
      "source": [
        "# for idx, (inputs, targets) in enumerate(loader_test):\n",
        "#     # The input is the first sequence\n",
        "#     inputs = inputs[0:1].to(device)\n",
        "#     # Decode input sequence of indices to sequences of word/tokens\n",
        "#     src_labels = vocab_in.lookup_tokens(inputs[0].cpu().numpy().tolist())\n",
        "\n",
        "#     # Translate input sequence into predicted target sequence\n",
        "#     decoded_indices, attention_weights = translate(model, inputs)\n",
        "\n",
        "#     # Decode target sequence of indices to sequences of word/tokens\n",
        "#     tgt_labels = vocab_out.lookup_tokens(decoded_indices)\n",
        "\n",
        "#     # Print input and translation\n",
        "#     print(' '.join(src_labels))\n",
        "#     print()\n",
        "#     print(' '.join(tgt_labels))\n",
        "\n",
        "#     # Break the loop; we only want to check a single batch with a single sentence\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJWEU6vLxY3n",
        "outputId": "4c11b856-cc6d-40f2-d4d1-0651bf97fcf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32100\n",
            "▁Dear ▁all , ▁I <unk> ▁your <unk> <unk> <unk> <unk> ▁in ▁the <unk> ▁and ▁I ▁am ▁very <unk> ▁in <unk> ▁in ▁your <unk> <unk> . ▁I ▁think ▁I ▁am ▁the <unk> <unk> ▁for ▁you . ▁My <unk> ▁is <unk> a ▁and ▁I ▁am <unk> ▁years <unk> . ▁I ▁am <unk> ▁the <unk> <unk> <unk> ▁for ▁the <unk> ▁year . ▁For <unk> <unk> ▁I ▁have <unk> ▁been ▁on ▁the <unk> ▁position ▁on ▁ a <unk> ▁and ▁looked ▁after ▁the <unk> <unk> <unk> <unk> . ▁I ▁usually <unk> ▁games ▁with <unk> ▁and <unk> ▁to <unk> ▁for ▁the <unk> <unk> . ▁In ▁the <unk> s ▁we <unk> <unk> ▁games ▁which ▁we ▁usually ▁had ▁not <unk> <unk> <unk> . <unk> ▁I <unk> ▁to <unk> ▁my <unk> <unk> ▁I <unk> ▁to ▁go ▁with ▁you ▁on ▁ a <unk> . ▁I <unk> ▁that ▁the <unk> ▁which <unk> ▁your <unk> ▁are <unk> ▁all <unk> ▁the ▁world . ▁My <unk> ▁dream ▁is ▁to <unk> <unk> <unk> <unk> ly . ▁I ▁am ▁ a ▁very ▁good ▁hard <unk> ▁and ▁I ▁do ▁not ▁have ▁any <unk> ▁with <unk> ▁in <unk> s ▁and ▁ <unk> ▁the <unk> ▁for ▁the <unk> ▁and ▁my <unk> . ▁I ▁am ▁looking ▁forward ▁to ▁your <unk> . <unk> <unk> . ▁ </s>\n",
            "\n",
            ". ▁I ▁I . . . . . . . . . . ▁I . . . . . . . . . . ▁I . . . . . . . . . . . ▁I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "\n",
            "Dear all, I<unk> your<unk><unk><unk><unk> in the<unk> and I am very<unk> in<unk> in your<unk><unk>. I think I am the<unk><unk> for you. My<unk> is<unk>a and I am<unk> years<unk>. I am<unk> the<unk><unk><unk> for the<unk> year. For<unk><unk> I have<unk> been on the<unk> position on a<unk> and looked after the<unk><unk><unk><unk>. I usually<unk> games with<unk> and<unk> to<unk> for the<unk><unk>. In the<unk>s we<unk><unk> games which we usually had not<unk><unk><unk>.<unk> I<unk> to<unk> my<unk><unk> I<unk> to go with you on a<unk>. I<unk> that the<unk> which<unk> your<unk> are<unk> all<unk> the world. My<unk> dream is to<unk><unk><unk><unk>ly. I am a very good hard<unk> and I do not have any<unk> with<unk> in<unk>s and <unk> the<unk> for the<unk> and my<unk>. I am looking forward to your<unk>.<unk><unk>. </s>. I I.......... I.......... I........... I...............................................................\n",
            "\n",
            "\n",
            "Dear <unk> I<unk> your<unk> in the<unk> and I am very<unk> in<unk> in your<unk><unk>. I think I am the<unk><unk> for you. My<unk> is<unk>a and I am<unk> years<unk>. I am studying at the<unk><unk><unk> in the<unk> year. I have<unk> worked in a<unk> position on a<unk><unk><unk> and looked after<unk><unk><unk><unk>. I usually<unk> games with<unk> and<unk> to<unk> for<unk><unk>. In the<unk>s, we<unk><unk> games which we usually had not<unk><unk>.<unk> I<unk> to<unk> my<unk><unk>, I<unk> to go with you on a<unk>. I<unk> that the<unk> who<unk> your<unk> are from all<unk> the world. My<unk> dream is to<unk><unk><unk><unk><unk>. I am a very good hard<unk> and I do not have any<unk> with<unk> in<unk>s and <unk> the<unk> for the<unk> and my<unk>. I am looking forward to your<unk>.<unk><unk>. </s>\n"
          ]
        }
      ],
      "source": [
        "all_vocab = tokenizer.get_vocab()\n",
        "print(len(tokenizer))\n",
        "\n",
        "correct_sents= []\n",
        "result_sents= []\n",
        "\n",
        "\n",
        "# post processing to get final sentence from decoded outputs\n",
        "for idx, (inputs, targets) in enumerate(loader_test):\n",
        "    # The input is the first sequence\n",
        "    inputs = inputs[0:1].to(device)\n",
        "    # Decode input sequence of indices to sequences of word/tokens\n",
        "    src_labels = vocab_in.lookup_tokens(inputs[0].cpu().numpy().tolist())\n",
        "\n",
        "    # Translate input sequence into predicted target sequence\n",
        "    decoded_indices, attention_weights = translate(model, inputs)\n",
        "\n",
        "    # Decode target sequence of indices to sequences of word/tokens\n",
        "    tgt_labels = vocab_out.lookup_tokens(decoded_indices)\n",
        "\n",
        "    # Print input and translation\n",
        "    print(' '.join(src_labels))\n",
        "    print()\n",
        "    print(' '.join(tgt_labels))\n",
        "    print()\n",
        "\n",
        "    # map to t5 tokenizer encodings\n",
        "    src_indices = []\n",
        "    for i, label in enumerate(src_labels):\n",
        "        if label == SOS_TOKEN:\n",
        "          src_indices.append(all_vocab[\"<pad>\"])\n",
        "        elif label in all_vocab:\n",
        "          src_indices.append(all_vocab[label])\n",
        "        else :\n",
        "          src_indices.append(all_vocab[\"<unk>\"])\n",
        "\n",
        "    tgt_indices = []\n",
        "    for i, label in enumerate(tgt_labels):\n",
        "        if label == SOS_TOKEN:\n",
        "          src_indices.append(all_vocab[\"<pad>\"])\n",
        "        elif label in all_vocab:\n",
        "          src_indices.append(all_vocab[label])\n",
        "        else :\n",
        "          src_indices.append(all_vocab[\"<unk>\"])\n",
        "\n",
        "    print(tokenizer.decode(src_indices))\n",
        "    print()\n",
        "    print(tokenizer.decode(tgt_indices))\n",
        "\n",
        "    result_sents.append(tokenizer.decode(tgt_indices)) # hypothesis\n",
        "\n",
        "    # get correct sentence from dataset (for references)\n",
        "    targets = targets[0:1].to(device)\n",
        "\n",
        "    # Decode input sequence of indices to sequences of word/tokens\n",
        "    target_labels = vocab_out.lookup_tokens(targets[0].cpu().numpy().tolist())\n",
        "    label_indices = []\n",
        "    for i, label in enumerate(target_labels):\n",
        "        if label == SOS_TOKEN:\n",
        "            src_indices.append(all_vocab[\"<pad>\"])\n",
        "        elif label in all_vocab:\n",
        "            label_indices.append(all_vocab[label])\n",
        "        else :\n",
        "            label_indices.append(all_vocab[\"<unk>\"])\n",
        "\n",
        "    correct_sents.append(tokenizer.decode(label_indices)) # save references\n",
        "    print(tokenizer.decode(label_indices))\n",
        "\n",
        "\n",
        "    # Break the loop; we only want to check a single batch with a single sentence\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxzd477279TE"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def write_expected_actual_to_csv(expected, actual, output_file):\n",
        "    with open(output_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['Expected', 'Actual'])\n",
        "        for exp, act in zip(expected, actual):\n",
        "            writer.writerow([exp, act])\n",
        "\n",
        "# Example usage:\n",
        "expected_list = correct_sents\n",
        "actual_list = result_sents\n",
        "output_file = \"validation_results.csv\"\n",
        "\n",
        "write_expected_actual_to_csv(expected_list, actual_list, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoXAIqQTbCEn",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "weights = attention_weights.detach().cpu().numpy()\n",
        "\n",
        "print(src_labels)\n",
        "print(tgt_labels)\n",
        "\n",
        "plot_attention_weights(weights, src_labels, tgt_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoB9v469iFXV"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e09659b00b94be6852a25275dcb3d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b09127a0ca974b33904240eab8b5960e",
            "placeholder": "​",
            "style": "IPY_MODEL_2d33a774753847e0b68ffa00919686cc",
            "value": " 300/300 [00:00&lt;00:00, 715.94 examples/s]"
          }
        },
        "1566a39b22de427192f7660c6d0902bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf57322b901404191a55fc1921f5f1f",
            "placeholder": "​",
            "style": "IPY_MODEL_9441586eaa9e48e896cdc9629c33f63d",
            "value": "Map: 100%"
          }
        },
        "2d33a774753847e0b68ffa00919686cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a9475f602bf4487a0429ede0064c6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9441586eaa9e48e896cdc9629c33f63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f75f8f8668c4124927c8d62c7dea2cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09127a0ca974b33904240eab8b5960e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd35b484f9084ec0b6d690f7a4ad2463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1566a39b22de427192f7660c6d0902bb",
              "IPY_MODEL_e0091a27b90c4e3ab75f38a0c3ea4afa",
              "IPY_MODEL_0e09659b00b94be6852a25275dcb3d1a"
            ],
            "layout": "IPY_MODEL_5a9475f602bf4487a0429ede0064c6d6"
          }
        },
        "e0091a27b90c4e3ab75f38a0c3ea4afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f75f8f8668c4124927c8d62c7dea2cd",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff1f8fcae7cd43ac89eee00ce81b3e6f",
            "value": 300
          }
        },
        "fdf57322b901404191a55fc1921f5f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1f8fcae7cd43ac89eee00ce81b3e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
