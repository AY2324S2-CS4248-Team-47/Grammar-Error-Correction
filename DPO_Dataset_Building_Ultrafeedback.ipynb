{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKdZxFqU0w2-"
      },
      "source": [
        "# DPO Dataset Building - Ultrafeedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2zLfZxo05N2"
      },
      "source": [
        "For a list of gramatically incorrect sentences sampled from the train dataset, genarate a chosen and rejected correction, using LLMs.\n",
        "\n",
        "- Chosen: GPT-4\n",
        "- Rejected: Mistral 8x7B Instruct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXV5wldeZDhK"
      },
      "source": [
        "## Downloading required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZlw1Ctb0v9a"
      },
      "outputs": [],
      "source": [
        "!pip install datasets openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oUeqycqZNKj"
      },
      "source": [
        "## Importing required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQO8FPZvz23e"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset, Dataset, concatenate_datasets\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "from huggingface_hub import login as hf_login\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juQ2bzgeCXZz"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v_rXa-j7wOP"
      },
      "source": [
        "### GPT-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhsNKWI47yyl"
      },
      "outputs": [],
      "source": [
        "openai_api_key = input(\"Enter OpenAI API key: \")\n",
        "openai_client = OpenAI(api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i3ruSO5C3v8"
      },
      "outputs": [],
      "source": [
        "chosen_list = []\n",
        "def get_gpt4_outputs(start, size):\n",
        "    prompt = \"Rewrite the given text without grammatical, spelling and punctuation errors. Make as few corrections as possible. Give only the corrected version of the text.\"\n",
        "\n",
        "    with tqdm(total=size) as pbar:\n",
        "        for txt in train_dataset[start: start + size]['text']:\n",
        "            completion = openai_client.chat.completions.create(\n",
        "                model=\"gpt-4-turbo-preview\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": prompt},\n",
        "                    {\"role\": \"user\", \"content\": txt.strip()}\n",
        "                ],\n",
        "                temperature=0.5,\n",
        "                max_tokens=512,\n",
        "                top_p=1,\n",
        "                frequency_penalty=0,\n",
        "                presence_penalty=0\n",
        "            )\n",
        "\n",
        "            chosen_list.append(completion.choices[0].message.content.strip())\n",
        "            pbar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvfWyidiVTx_"
      },
      "source": [
        "### Mistral 8x7B Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZaiW7yhVTIi"
      },
      "outputs": [],
      "source": [
        "hf_token = input(\"Enter HuggingFace token: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZsek9cGVauV"
      },
      "outputs": [],
      "source": [
        "MISTRAL_API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
        "\n",
        "rejected_list = []\n",
        "def get_mistral_outputs(start, size):\n",
        "    prompt = \"Rewrite the given text without grammatical, spelling and punctuation errors. Make as few corrections as possible. The text to be corrected begins after 'Text:'. Give only the corrected version of the text. Text: \"\n",
        "\n",
        "    with tqdm(total=size) as pbar:\n",
        "        for txt in train_dataset[start: start + size]['text']:\n",
        "            input_text = f\"<s>[INST]{prompt}{txt.strip()}[/INST]\"\n",
        "            payload = {\n",
        "                \"inputs\": input_text,\n",
        "                \"parameters\": {\n",
        "                    \"max_new_tokens\": 512\n",
        "                }\n",
        "            }\n",
        "            response = requests.post(MISTRAL_API_URL, headers=headers, json=payload).json()\n",
        "\n",
        "            while not(response) or type(response) != list or len(response) == 0:\n",
        "                response = requests.post(MISTRAL_API_URL, headers=headers, json=payload).json()\n",
        "\n",
        "            rejected_list.append(response[0]['generated_text'][len(input_text):].strip())\n",
        "            pbar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXp9BcFAGwIX"
      },
      "source": [
        "## Building the DPO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL8jULPiG9Tj"
      },
      "source": [
        "### Get the WI-LOCNESS dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ_XEqrQGyGZ"
      },
      "outputs": [],
      "source": [
        "raw_datasets = load_dataset(\"wi_locness\", 'wi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6JFaRYDHJjK"
      },
      "outputs": [],
      "source": [
        "dataset_dict = raw_datasets[\"train\"].train_test_split(test_size=0.1, seed=0)\n",
        "raw_datasets[\"train\"] = dataset_dict[\"train\"]\n",
        "raw_datasets[\"test\"] = dataset_dict[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-3b-4e1t\")\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]', 'unk_token': '[UNK]'})\n",
        "raw_datasets = raw_datasets.filter(lambda x: len(tokenizer.encode(x[\"text\"])) <= 450)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TNtgp-IWXGb"
      },
      "outputs": [],
      "source": [
        "train_dataset = raw_datasets[\"train\"]\n",
        "train_dataset = train_dataset.remove_columns(column_names=[\"id\", \"userid\", \"cefr\", \"edits\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp9K59jE5bXc"
      },
      "source": [
        "### Build dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YRHScYA5ePH"
      },
      "outputs": [],
      "source": [
        "START = 0\n",
        "DATASET_SIZE = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hf_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_E7uF1TVL3Z"
      },
      "outputs": [],
      "source": [
        "get_mistral_outputs(START, DATASET_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVV3jsICVE_w"
      },
      "outputs": [],
      "source": [
        "get_gpt4_outputs(START, DATASET_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1byPVzV58Fb"
      },
      "outputs": [],
      "source": [
        "dpo_dataset_dict = {\n",
        "    \"chosen\": chosen_list,\n",
        "    \"prompt\": train_dataset[START: START + DATASET_SIZE]['text'],\n",
        "    \"rejected\": rejected_list\n",
        "}\n",
        "\n",
        "dpo_dataset = Dataset.from_dict(dpo_dataset_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dpo_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Overwrite the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BR0z0x0k6LPe"
      },
      "outputs": [],
      "source": [
        "dpo_dataset.push_to_hub(repo_id = \"AY2324S2-CS4248-Team-47/gec-dpo-ultrafeedback\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Append to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "existing_dataset = load_dataset(\"AY2324S2-CS4248-Team-47/gec-dpo-ultrafeedback\")['train']\n",
        "new_dataset = concatenate_datasets([existing_dataset, dpo_dataset])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_dataset.push_to_hub(repo_id = \"AY2324S2-CS4248-Team-47/gec-dpo-ultrafeedback\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
